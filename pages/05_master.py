"""ãƒã‚¹ã‚¿ç®¡ç†ãƒšãƒ¼ã‚¸ - å•†å“ã‚µã‚¤ã‚¯ãƒ«ãƒ»ã‚¢ãƒƒãƒ—ã‚»ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ»åºƒå‘ŠURL IDã®é–²è¦§ãƒ»ç·¨é›†."""

from __future__ import annotations

from difflib import SequenceMatcher

import pandas as pd
import streamlit as st

from src.bigquery_client import fetch_filter_options, fetch_filtered_options, get_bigquery_client
from src.config_loader import (
    load_ad_url_mappings,
    load_product_cycles,
    load_upsell_mappings,
    save_ad_url_mappings,
    save_product_cycles,
    save_upsell_mappings,
)
from src.constants import Col
from src.queries.common import get_table_ref
from src.session import get_selected_company_key

st.header("ãƒã‚¹ã‚¿ç®¡ç†")

tab_cycles, tab_upsell, tab_ad_url = st.tabs(["å•†å“ã‚µã‚¤ã‚¯ãƒ«", "ã‚¢ãƒƒãƒ—ã‚»ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°", "åºƒå‘ŠURL ID"])


# =====================================================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼: é¡ä¼¼åº¦ã‚½ãƒ¼ãƒˆ
# =====================================================================
def _similarity(a: str, b: str) -> float:
    """2æ–‡å­—åˆ—ã®é¡ä¼¼åº¦ (0~1)."""
    return SequenceMatcher(None, a, b).ratio()


def _sort_by_similarity(candidates: list[str], reference: str) -> list[str]:
    """reference ã«é¡ä¼¼åº¦ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ."""
    if not reference:
        return candidates
    return sorted(candidates, key=lambda c: _similarity(reference, c), reverse=True)


# =====================================================================
# å•†å“åä¸€è¦§ã®å–å¾— (BigQuery)
# =====================================================================
@st.cache_data(ttl=86400, show_spinner=False)
def _fetch_all_product_names(company_key: str) -> list[str]:
    """é¸æŠä¸­ã®ä¼šç¤¾ã®BigQueryã‹ã‚‰å®šæœŸå•†å“åä¸€è¦§ã‚’å–å¾—."""
    client = get_bigquery_client()
    table_ref = get_table_ref(company_key)
    return fetch_filter_options(client, table_ref, Col.SUBSCRIPTION_PRODUCT_NAME)


@st.cache_data(ttl=86400, show_spinner=False)
def _fetch_product_categories(company_key: str) -> list[str]:
    """å•†å“ã‚«ãƒ†ã‚´ãƒªä¸€è¦§ã‚’å–å¾—."""
    client = get_bigquery_client()
    table_ref = get_table_ref(company_key)
    return fetch_filter_options(client, table_ref, Col.PRODUCT_CATEGORY)


@st.cache_data(ttl=86400, show_spinner=False)
def _fetch_product_names_by_category(
    company_key: str, categories: tuple[str, ...],
) -> list[str]:
    """å•†å“ã‚«ãƒ†ã‚´ãƒªã§çµã‚Šè¾¼ã‚“ã å®šæœŸå•†å“åä¸€è¦§ã‚’å–å¾—."""
    client = get_bigquery_client()
    table_ref = get_table_ref(company_key)
    return fetch_filtered_options(
        client, table_ref, Col.SUBSCRIPTION_PRODUCT_NAME,
        {Col.PRODUCT_CATEGORY: list(categories)},
    )


# =====================================================================
# å•†å“ã‚µã‚¤ã‚¯ãƒ«ã‚¿ãƒ–
# =====================================================================
with tab_cycles:
    st.subheader("å•†å“ååˆ¥ ç™ºé€ã‚µã‚¤ã‚¯ãƒ«")
    st.caption("å•†å“åã”ã¨ã®ç™ºé€é–“éš”ã‚’ç®¡ç†ã—ã¾ã™ã€‚è¡Œã®è¿½åŠ ãƒ»å‰Šé™¤ã‚‚å¯èƒ½ã§ã™ã€‚")

    data = load_product_cycles()
    products = data.get("products", [])
    defaults = data.get("defaults", {"cycle1": 30, "cycle2": 30})

    df = pd.DataFrame(products) if products else pd.DataFrame(columns=["name", "cycle1", "cycle2"])

    # --- æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ ---
    cycle_search = st.text_input(
        "å•†å“åã§æ¤œç´¢",
        placeholder="æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...",
        key="cycle_search",
    )

    if cycle_search.strip():
        keyword = cycle_search.strip()
        filtered_df = df[df["name"].str.contains(keyword, case=False, na=False)]
        st.info(f"ğŸ” {len(filtered_df)} / {len(df)} ä»¶ãŒãƒ’ãƒƒãƒˆ  â€”  ãƒ•ã‚£ãƒ«ã‚¿ã‚’è§£é™¤ã™ã‚‹ã¨ç·¨é›†å¯èƒ½ã«ãªã‚Šã¾ã™")
        st.dataframe(
            filtered_df,
            column_config={
                "name": st.column_config.TextColumn("å•†å“å", width="large"),
                "cycle1": st.column_config.NumberColumn("åˆå›â†’2å›ç›® (æ—¥)"),
                "cycle2": st.column_config.NumberColumn("2å›ç›®ä»¥é™ (æ—¥)"),
            },
            use_container_width=True,
            height=600,
        )
    else:
        edited_df = st.data_editor(
            df,
            num_rows="dynamic",
            column_config={
                "name": st.column_config.TextColumn("å•†å“å", required=True, width="large"),
                "cycle1": st.column_config.NumberColumn("åˆå›â†’2å›ç›® (æ—¥)", min_value=1, default=30),
                "cycle2": st.column_config.NumberColumn("2å›ç›®ä»¥é™ (æ—¥)", min_value=1, default=30),
            },
            use_container_width=True,
            height=600,
            key="cycle_editor",
        )

        col_save, col_default = st.columns([1, 2])
        with col_save:
            if st.button("ä¿å­˜", type="primary", key="save_cycles"):
                new_data = {
                    "products": edited_df.dropna(subset=["name"]).to_dict("records"),
                    "defaults": defaults,
                }
                save_product_cycles(new_data)
                st.success(f"{len(new_data['products'])} ä»¶ã®å•†å“ã‚µã‚¤ã‚¯ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
                st.rerun()

        with col_default:
            st.markdown(f"**ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤**: åˆå›â†’2å›ç›® = {defaults['cycle1']}æ—¥ / 2å›ç›®ä»¥é™ = {defaults['cycle2']}æ—¥")


# =====================================================================
# ã‚¢ãƒƒãƒ—ã‚»ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ã‚¿ãƒ–
# =====================================================================
with tab_upsell:
    st.subheader("ã‚¢ãƒƒãƒ—ã‚»ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°")
    st.caption("ã‚¢ãƒƒãƒ—ã‚»ãƒ«ç‡ = åˆ†å­(äººæ•°) / åˆ†æ¯(äººæ•°) Ã— 100")

    # --- å•†å“åä¸€è¦§ã‚’å–å¾— ---
    company_key = get_selected_company_key()
    if not company_key:
        st.warning("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ä¼šç¤¾ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    else:
        # --- å•†å“ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ ---
        categories = _fetch_product_categories(company_key)
        selected_categories = st.multiselect(
            "å•†å“ã‚«ãƒ†ã‚´ãƒªã§çµã‚Šè¾¼ã¿",
            categories,
            key="master_upsell_category_filter",
            help="é¸æŠã™ã‚‹ã¨ã€åˆ†å­ãƒ»åˆ†æ¯ãƒ»æœŸé–“ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å€™è£œãŒã“ã®ã‚«ãƒ†ã‚´ãƒªã®å•†å“ã®ã¿ã«çµã‚Šè¾¼ã¾ã‚Œã¾ã™",
        )

        if selected_categories:
            all_product_names: list[str] = _fetch_product_names_by_category(
                company_key, tuple(selected_categories),
            )
        else:
            all_product_names: list[str] = _fetch_all_product_names(company_key)

        mappings = load_upsell_mappings()

        # ========== ã‚«ãƒ¼ãƒ‰å½¢å¼ã®ç·¨é›†UI ==========

        # session_state ã§ãƒãƒƒãƒ”ãƒ³ã‚°ãƒªã‚¹ãƒˆã‚’ç®¡ç†
        if "upsell_mappings_edit" not in st.session_state:
            st.session_state["upsell_mappings_edit"] = mappings if mappings else []

        edit_mappings: list[dict] = st.session_state["upsell_mappings_edit"]

        for idx, m in enumerate(edit_mappings):
            with st.container(border=True):
                header_col, del_col = st.columns([10, 1])
                with del_col:
                    if st.button("ğŸ—‘ï¸", key=f"del_{idx}", help="ã“ã®è¡Œã‚’å‰Šé™¤"):
                        edit_mappings.pop(idx)
                        st.session_state["upsell_mappings_edit"] = edit_mappings
                        st.rerun()

                # --- ãƒãƒƒãƒ”ãƒ³ã‚°å (text_input) ---
                with header_col:
                    current_label = m.get("label", f"ãƒãƒƒãƒ”ãƒ³ã‚° {idx + 1}")
                    sel_label = st.text_input(
                        "ãƒãƒƒãƒ”ãƒ³ã‚°å",
                        value=current_label,
                        key=f"label_{idx}",
                    )
                    m["label"] = sel_label

                # é¡ä¼¼åº¦ã‚½ãƒ¼ãƒˆã®åŸºæº–
                ref_name = (m.get("numerator_names") or [""])[0]
                sorted_candidates = _sort_by_similarity(all_product_names, ref_name)

                # --- åˆ†å­ (multiselect) ---
                current_numerators = m.get("numerator_names", [])
                num_options = list(sorted_candidates)
                for cv in current_numerators:
                    if cv and cv not in num_options:
                        num_options.insert(0, cv)

                sel_numerators = st.multiselect(
                    "åˆ†å­ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    num_options,
                    default=current_numerators,
                    key=f"numerator_{idx}",
                )
                m["numerator_names"] = sel_numerators

                # --- åˆ†æ¯ (multiselect) ---
                current_denominators = m.get("denominator_names", [])
                den_options = list(sorted_candidates)
                for cv in current_denominators:
                    if cv and cv not in den_options:
                        den_options.insert(0, cv)

                sel_denominators = st.multiselect(
                    "åˆ†æ¯ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    den_options,
                    default=current_denominators,
                    key=f"denominator_{idx}",
                )
                m["denominator_names"] = sel_denominators

                # --- æœŸé–“ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ (multiselect) ---
                current_period_ref = m.get("period_ref_names", [])
                period_ref_name = (current_period_ref or [""])[0] or ref_name
                sorted_period = _sort_by_similarity(all_product_names, period_ref_name)
                period_options = list(sorted_period)
                for cv in current_period_ref:
                    if cv and cv not in period_options:
                        period_options.insert(0, cv)

                sel_period_ref = st.multiselect(
                    "æœŸé–“ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆã“ã®å•†å“ã®å®šæœŸé–‹å§‹æ—¥ã®ç¯„å›²ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœŸé–“ã«ã™ã‚‹ï¼‰",
                    period_options,
                    default=current_period_ref,
                    key=f"period_ref_{idx}",
                )
                m["period_ref_names"] = sel_period_ref

        # --- è¡Œè¿½åŠ ãƒœã‚¿ãƒ³ ---
        if st.button("ï¼‹ ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’è¿½åŠ ", key="add_mapping"):
            edit_mappings.append({
                "label": "",
                "numerator_names": [],
                "denominator_names": [],
                "period_ref_names": [],
            })
            st.session_state["upsell_mappings_edit"] = edit_mappings
            st.rerun()

        # --- ä¿å­˜ãƒœã‚¿ãƒ³ ---
        st.markdown("")
        if st.button("ä¿å­˜", type="primary", key="save_upsell"):
            valid_mappings = [
                m for m in edit_mappings
                if m.get("numerator_names") and m.get("denominator_names")
            ]
            save_upsell_mappings(valid_mappings)
            st.session_state["upsell_mappings_edit"] = valid_mappings
            st.success(f"{len(valid_mappings)} ä»¶ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
            st.rerun()


# =====================================================================
# åºƒå‘ŠURL IDã‚¿ãƒ–
# =====================================================================
@st.cache_data(ttl=86400, show_spinner=False)
def _fetch_all_ad_url_ids(company_key: str) -> list[str]:
    """BigQueryã‹ã‚‰åºƒå‘ŠURL IDä¸€è¦§ã‚’å–å¾—."""
    client = get_bigquery_client()
    table_ref = get_table_ref(company_key)
    return fetch_filter_options(client, table_ref, Col.AD_URL)


with tab_ad_url:
    st.subheader("åºƒå‘ŠURL ID â†’ åºƒå‘ŠURLå ãƒãƒƒãƒ”ãƒ³ã‚°")
    st.caption(
        "åºƒå‘ŠURL IDã«è¡¨ç¤ºåã‚’ç´ä»˜ã‘ã¾ã™ã€‚"
        "åå‰ãŒå®šç¾©ã•ã‚ŒãŸIDã¯ãƒ•ã‚£ãƒ«ã‚¿ã§åå‰è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
        "æœªå®šç¾©ã®IDã¯ãã®ã¾ã¾IDã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
    )

    company_key_ad = get_selected_company_key()
    if not company_key_ad:
        st.warning("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ä¼šç¤¾ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    else:
        # BigQueryã‹ã‚‰å…¨åºƒå‘ŠURL IDã‚’å–å¾—
        all_ad_url_ids = _fetch_all_ad_url_ids(company_key_ad)

        # æ—¢å­˜ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿
        existing_mappings = load_ad_url_mappings()
        existing_map = {m["ad_url_id"]: m.get("ad_url_name", "") for m in existing_mappings}

        # BigQueryã«ã‚ã‚‹IDã§æ—¢å­˜ãƒãƒƒãƒ”ãƒ³ã‚°ã«ãªã„ã‚‚ã®ã‚’è¿½åŠ ï¼ˆåå‰ã¯ç©ºï¼‰
        merged: list[dict] = []
        seen_ids: set[str] = set()

        # æ—¢å­˜ãƒãƒƒãƒ”ãƒ³ã‚°åˆ†ã‚’å…ˆã«è¿½åŠ 
        for m in existing_mappings:
            aid = m.get("ad_url_id", "")
            if aid:
                merged.append({
                    "ad_url_id": aid,
                    "ad_url_name": m.get("ad_url_name", ""),
                })
                seen_ids.add(aid)

        # BigQueryã«ã‚ã£ã¦æœªç™»éŒ²ã®IDã‚’è¿½åŠ 
        for aid in all_ad_url_ids:
            if aid not in seen_ids:
                merged.append({"ad_url_id": aid, "ad_url_name": ""})
                seen_ids.add(aid)

        # DataFrameã«å¤‰æ›
        df_ad = pd.DataFrame(merged, columns=["ad_url_id", "ad_url_name"])

        # --- æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ ---
        ad_search = st.text_input(
            "IDã¾ãŸã¯åå‰ã§æ¤œç´¢",
            placeholder="æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰...",
            key="ad_url_search",
        )

        # æ¤œç´¢ã®æœ‰ç„¡ã§è¡¨ç¤ºã‚’åˆ†å²ï¼ˆã©ã¡ã‚‰ã‚‚ç·¨é›†å¯èƒ½ï¼‰
        if ad_search.strip():
            kw = ad_search.strip()
            mask = (
                df_ad["ad_url_id"].str.contains(kw, case=False, na=False)
                | df_ad["ad_url_name"].str.contains(kw, case=False, na=False)
            )
            filtered_ad = df_ad[mask].copy()
            st.info(f"ğŸ” {len(filtered_ad)} / {len(df_ad)} ä»¶ãŒãƒ’ãƒƒãƒˆ")

            edited_ad = st.data_editor(
                filtered_ad,
                column_config={
                    "ad_url_id": st.column_config.TextColumn(
                        "åºƒå‘ŠURL ID", width="large", disabled=True,
                    ),
                    "ad_url_name": st.column_config.TextColumn(
                        "åºƒå‘ŠURLå", width="large",
                    ),
                },
                use_container_width=True,
                height=600,
                key="ad_url_editor_filtered",
            )

            if st.button("ä¿å­˜", type="primary", key="save_ad_url"):
                # ç·¨é›†ã•ã‚ŒãŸè¡Œã‚’ãƒãƒ¼ã‚¸: æ¤œç´¢çµæœã®ç·¨é›†å†…å®¹ã§å…ƒãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
                edited_map = {
                    r["ad_url_id"]: r.get("ad_url_name", "")
                    for r in edited_ad.to_dict("records")
                    if r.get("ad_url_id", "").strip()
                }
                save_data = []
                for r in df_ad.to_dict("records"):
                    aid = r.get("ad_url_id", "")
                    if not aid.strip():
                        continue
                    if aid in edited_map:
                        r["ad_url_name"] = edited_map[aid]
                    save_data.append(r)
                save_ad_url_mappings(save_data)
                st.success(
                    f"{len(save_data)} ä»¶ã®åºƒå‘ŠURL IDãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚"
                )
                st.rerun()
        else:
            edited_ad = st.data_editor(
                df_ad,
                num_rows="dynamic",
                column_config={
                    "ad_url_id": st.column_config.TextColumn(
                        "åºƒå‘ŠURL ID", required=True, width="large",
                    ),
                    "ad_url_name": st.column_config.TextColumn(
                        "åºƒå‘ŠURLå", width="large",
                    ),
                },
                use_container_width=True,
                height=600,
                key="ad_url_editor",
            )

            if st.button("ä¿å­˜", type="primary", key="save_ad_url_all"):
                save_data = (
                    edited_ad.dropna(subset=["ad_url_id"])
                    .to_dict("records")
                )
                save_data = [r for r in save_data if r.get("ad_url_id", "").strip()]
                save_ad_url_mappings(save_data)
                st.success(
                    f"{len(save_data)} ä»¶ã®åºƒå‘ŠURL IDãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚"
                )
                st.rerun()
